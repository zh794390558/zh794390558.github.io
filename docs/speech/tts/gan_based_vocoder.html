

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>GAN Based Vocoder &mdash; zh794390558.github.io 1.0 documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> zh794390558.github.io
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction.html">Hui Zhang</a></li>
</ul>
<p class="caption"><span class="caption-text">Speech</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../asr/chinese_syllable.html">chinese syllable</a></li>
<li class="toctree-l1"><a class="reference internal" href="../asr/alignment.html">Alignment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../asr/edit-distance-papers/README.html">ASR Edit-distance as objective function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../decode/decoding.html">Decoding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lm/ppl.html"><strong>语言模型评价指标Perplexity</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../lm/ngram_lm.html">Ngram LM</a></li>
<li class="toctree-l1"><a class="reference internal" href="README.html">TTS</a></li>
<li class="toctree-l1"><a class="reference internal" href="speech_synthesis.html">Speech Synthesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="TTS-papers/README.html">TTS papers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../text_process/crf.html">CRF(Conditional Random Fields)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../text_process/asr_text_backend.html">ASR Text Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../text_process/tts_text_frontend.html">Text Front End</a></li>
<li class="toctree-l1"><a class="reference internal" href="../vad/vad.html">VAD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spk/README.html">Speaker Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../separation/README.html">Speech Separation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../io/README.html">Speech I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="../io/praat_textgrid.html">Praat and TextGrid</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/training/speech_features.html">Speech Features</a></li>
</ul>
<p class="caption"><span class="caption-text">Coding</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../coding/cpp.html">library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/algorithm.html">Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/tutorials.html">Coding Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/aot/python_to_cpp.html">Python code to Cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/linear_algebra.html">线性代数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/hpc.html">HPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/eigen.html">Eigen</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/eigen.html#id11">矩阵和向量的运算</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/eigen.html#array">Array类和元素级操作</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/eigen.html#id27">块操作</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/eigen.html#id32">高级初始化方法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/eigen.html#id37">归约、迭代器和广播</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/eigen.html#map">原生缓存的接口：Map类</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/cuda.html">CUDA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/simd.html">SIMD</a></li>
</ul>
<p class="caption"><span class="caption-text">Developer guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../development/tfrt.html">TFRT: A New TensorFlow Runtime </a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/docker.html">Develop with Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/deltann_compile.html">Tensorflow compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/adding_op.html">Adding Tensorflow Op</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/serving.html">Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/tensorrt.html">TensorRT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/model_optimization.html">Model Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/contributing.html">Contributing Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/version.html">Version</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/linux.html">Tmux</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/linux.html#file-encoding">File Encoding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/linux.html#ubuntu-gcc-update">Ubuntu GCC Update</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/linux.html#centos-7-gcc-update">CentOS 7 gcc update</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/linux.html#nfs-mount">NFS Mount</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/linux.html#nginx">Nginx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/ffmpeg.html">FFPMEG</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/tools.html">Useful Tools</a></li>
</ul>
<p class="caption"><span class="caption-text">Production</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../product/product_value.html">用户体验、用户价值和产品价值</a></li>
</ul>
<p class="caption"><span class="caption-text">Dataset</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dataset.html">Dataset</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">zh794390558.github.io</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>GAN Based Vocoder</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/speech/tts/gan_based_vocoder.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="gan-based-vocoder">
<h1>GAN Based Vocoder<a class="headerlink" href="#gan-based-vocoder" title="Permalink to this headline">¶</a></h1>
<p><strong>声码器</strong>的总结如下:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th><strong>模型类型</strong></th>
<th><strong>模型</strong></th>
<th><strong>合成语音质量</strong></th>
<th><strong>效率</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>AR</td>
<td>WaveNet</td>
<td>非常好</td>
<td>非常差</td>
</tr>
<tr>
<td>AR</td>
<td>WaveRNN</td>
<td>非常好</td>
<td>中等</td>
</tr>
<tr>
<td>AR</td>
<td>Multiband WaveRNN</td>
<td>非常好</td>
<td>中等</td>
</tr>
<tr>
<td>AR</td>
<td>LPCNET</td>
<td>非常好</td>
<td>挺好的</td>
</tr>
<tr>
<td>Non-AR</td>
<td>Parallel WaveNet</td>
<td>非常好</td>
<td>还不错</td>
</tr>
<tr>
<td>Non-AR</td>
<td>WaveGlow</td>
<td>非常好</td>
<td>还不错</td>
</tr>
<tr>
<td>Non-AR</td>
<td>FlowWaveNet</td>
<td>非常好</td>
<td>还不错</td>
</tr>
<tr>
<td>GAN</td>
<td>ParallelWaveGAN</td>
<td>非常好</td>
<td>挺好的</td>
</tr>
<tr>
<td>GAN</td>
<td>MelGAN</td>
<td>挺好的</td>
<td>非常好</td>
</tr>
<tr>
<td>GAN</td>
<td>MB-MelGAN</td>
<td>非常好</td>
<td>非常非常好</td>
</tr>
</tbody>
</table><p>从上面表格中可以看到基于神经网络的声码器效果都挺好的，主要需要优化的就是生成的速度。出现了利用GAN的声码器之后，推理速度也极大的提高了。</p>
<p>There were several early attempts applying GANs to audio genera- tion tasks, but achieved limited success [6]. Recently, there has been a new wave of modeling audio using GANs, as non- AR models targeting to fast audio generation. Specifically, MelGAN [20], Parallel WaveGAN [21] and GAN-TTS [22] have shown promising performance on waveform generation tasks. They all rely on an adversarial game of two networks: a generator, which attempts to produce samples that mimic the reference distribution, and the discriminator, which tries to differentiate between real and generated samples. The in- put of MelGAN and Parallel WaveGAN is mel-spectrogram, while the input of GAN-TTS is linguistic features. Hence MelGAN and Parallel WaveGAN are considered as neural vocoders, while GAN-TTS is a stand-alone acoustic model. Meanwhile, Parallel WaveGAN and MelGAN both use auxil- iary loss, i.e., multi-resolution STFT loss and feature match- ing loss, respectively, so they converge significantly faster than GAN-TTS. Impressively, the pytorch implementation of MelGAN runs at more than 100x faster than real-time on GPU and more than 2x faster than real-time on CPU. On the contrast, the real-time factor of Parallel WaveGAN is limited because of the stacking of network layers. According to the provided demos, the speech synthesized by MelGAN and Parallel WaveGAN is not satisfactory with audible artifacts.</p>
<div class="section" id="gan-vocoder">
<h2>GAN Vocoder<a class="headerlink" href="#gan-vocoder" title="Permalink to this headline">¶</a></h2>
<ol>
<li><p>Parallel WaveGan</p>
<p><img alt="pwgan" src="../../_images/pwgan.png" /></p>
<p>In the proposed method, only a non-autoregressive WaveNet model is trained by optimizing the combi- nation of multi-resolution short-time Fourier transform (STFT) and adversarial loss functions that enable the model to effectively capture the time-frequency distribution of the realistic speech wave- form.</p>
<p>In the STFT-based time-frequency representation of signals, there is a trade-off between time and frequency resolution; e.g., increasing window size gives higher frequency resolution while reducing temporal resolution.</p>
</li>
<li><p>MelGAN</p>
<p><img alt="melgan" src="../../_images/melgan.png" /></p>
</li>
<li><p>MB-MelGAN</p>
<p>Specifically, we improve the original MelGAN by the following aspects. First, we increase the receptive field of the generator, which is proven to be beneficial to speech genera- tion. Second, we substitute the feature matching loss with the multi-resolution STFT loss to better measure the difference between fake and real speech.</p>
<p>More importantly, we extend MelGAN with multi- band processing: the generator takes mel-spectrograms as in- put and produces sub-band signals which are subsequently summed back to full-band signals as discriminator input.</p>
<img src="../../_static/mbmelgan.png" alt="drawing" height="500" width="500"/></li>
<li><p>HiFi-GAN</p>
<p>As speech audio consists of sinusoidal signals with various periods, we demonstrate that modeling periodic patterns of an audio is crucial for enhancing sample quality.</p>
<p>We propose HiFi-GAN, which achieves both higher computational efficiency and sample quality than AR or flow-based models. As speech audio consists of sinusoidal signals with various periods, modeling the periodic patterns matters to generate realistic speech audio. Therefore, we propose a discriminator which consists of small sub-discriminators, each of which obtains only a specific periodic parts of raw waveforms. This architecture is the very ground of our model successfully synthesizing realistic speech audio. As we extract different parts of audio for the discriminator, we also design a module that places multiple residual blocks each of which observes patterns of various lengths in parallel, and apply it to the generator.</p>
<p>HiFi-GAN consists of one generator and two discriminators: multi-scale and multi-period discrimina- tors.</p>
<p><img alt="hifigan-g" src="../../_images/hifigan-g.png" /></p>
<p><img alt="hifigan-d" src="../../_images/hifigan-d.png" /></p>
<p>Note that MPD operates on disjoint samples of raw waveforms, whereas MSD operates on smoothed waveforms.</p>
<img src="../../_static/hifigan-detial.png" alt="drawing" height="500" width="600"/></li>
</ol>
</div>
<div class="section" id="repos">
<h2>Repos<a class="headerlink" href="#repos" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>https://github.com/kan-bayashi/ParallelWaveGAN</p></li>
<li><p>https://github.com/jik876/hifi-gan</p></li>
</ul>
</div>
<div class="section" id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><strong>PARALLEL WAVEGAN</strong>: A FAST WAVEFORM GENERATION MODEL BASED ON GENERATIVE ADVERSARIAL NETWORKS WITH MULTI-RESOLUTION SPECTROGRAM</p></li>
<li><p><strong>MelGAN</strong>*: Generative Adversarial Networks for Conditional Waveform Synthesis</p></li>
<li><p><strong>MULTI-BAND MELGAN</strong>: FASTERWAVEFORM GENERATION FOR HIGH-QUALITY TEXT-TO-SPEECH</p></li>
<li><p><strong>HiFi-GAN</strong>: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis</p></li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, Hui Zhang.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>