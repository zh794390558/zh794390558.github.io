

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Ngram LM &mdash; zh794390558.github.io 1.0 documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="TTS" href="../tts/README.html" />
    <link rel="prev" title="语言模型评价指标Perplexity" href="ppl.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> zh794390558.github.io
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction.html">Hui Zhang</a></li>
</ul>
<p class="caption"><span class="caption-text">Speech</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../asr/chinese_syllable.html">chinese syllable</a></li>
<li class="toctree-l1"><a class="reference internal" href="../asr/alignment.html">Alignment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../asr/edit-distance-papers/README.html">ASR Edit-distance as objective function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../decode/decoding.html">Decoding</a></li>
<li class="toctree-l1"><a class="reference internal" href="ppl.html"><strong>语言模型评价指标Perplexity</strong></a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Ngram LM</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#prepare-language-model">Prepare Language Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#english-lm">English LM</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mandarin-lm">Mandarin LM</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#kenlm">KenLM</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../tts/README.html">TTS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tts/speech_synthesis.html">Speech Synthesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tts/TTS-papers/README.html">TTS papers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../text_process/crf.html">CRF(Conditional Random Fields)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../text_process/asr_text_backend.html">ASR Text Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../text_process/tts_text_frontend.html">Text Front End</a></li>
<li class="toctree-l1"><a class="reference internal" href="../vad/vad.html">VAD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spk/README.html">Speaker Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../separation/README.html">Speech Separation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../io/README.html">Speech I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="../io/praat_textgrid.html">Praat and TextGrid</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/training/speech_features.html">Speech Features</a></li>
</ul>
<p class="caption"><span class="caption-text">Coding</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../coding/cpp.html">library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/algorithm.html">Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/tutorials.html">Coding Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/aot/python_to_cpp.html">Python code to Cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/linear_algebra.html">线性代数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/hpc.html">HPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/eigen.html">Eigen</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/eigen.html#id11">矩阵和向量的运算</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/eigen.html#array">Array类和元素级操作</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/eigen.html#id27">块操作</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/eigen.html#id32">高级初始化方法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/eigen.html#id37">归约、迭代器和广播</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/eigen.html#map">原生缓存的接口：Map类</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/cuda.html">CUDA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../coding/simd.html">SIMD</a></li>
</ul>
<p class="caption"><span class="caption-text">Developer guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../development/tfrt.html">TFRT: A New TensorFlow Runtime </a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/docker.html">Develop with Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/deltann_compile.html">Tensorflow compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/adding_op.html">Adding Tensorflow Op</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/serving.html">Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/tensorrt.html">TensorRT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/model_optimization.html">Model Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/contributing.html">Contributing Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/version.html">Version</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/linux.html">Linux</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/ffmpeg.html">FFPMEG</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development/tools.html">Useful Tools</a></li>
</ul>
<p class="caption"><span class="caption-text">Production</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../product/product_value.html">用户体验、用户价值和产品价值</a></li>
</ul>
<p class="caption"><span class="caption-text">Dataset</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dataset.html">Dataset</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">zh794390558.github.io</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Ngram LM</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/speech/lm/ngram_lm.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="ngram-lm">
<h1>Ngram LM<a class="headerlink" href="#ngram-lm" title="Permalink to this headline">¶</a></h1>
<div class="section" id="prepare-language-model">
<h2>Prepare Language Model<a class="headerlink" href="#prepare-language-model" title="Permalink to this headline">¶</a></h2>
<p>If you wish to train your own better language model, please refer to <a class="reference external" href="https://github.com/kpu/kenlm">KenLM</a> for tutorials.</p>
<div class="section" id="english-lm">
<h3>English LM<a class="headerlink" href="#english-lm" title="Permalink to this headline">¶</a></h3>
<p>There are some preprocessing steps before training:</p>
<ul class="simple">
<li><p>Characters not in ['A-Za-z0-9\s'] (\s represents whitespace characters) are removed and Arabic numbers are converted to English numbers like 1000 to one thousand.</p></li>
<li><p>Repeated whitespace characters are squeezed to one and the beginning whitespace characters are removed. Notice that all transcriptions are lowercase, so all characters are converted to lowercase.</p></li>
<li><p>Top 400,000 most frequent words are selected to build the vocabulary and the rest are replaced with 'UNKNOWNWORD'.</p></li>
</ul>
<p>Now the preprocessing is done and we get a clean corpus to train the language model. Our released language model are trained with agruments '-o 5 --prune 0 1 1 1 1'. '-o 5' means the max order of language model is 5. '--prune 0 1 1 1 1' represents count thresholds for each order and more specifically it will prune singletons for orders two and higher. To save disk storage we convert the arpa file to 'trie' binary file with arguments '-a 22 -q 8 -b 8'. '-a' represents the maximum number of leading bits of pointers in 'trie' to chop. '-q -b' are quantization parameters for probability and backoff.</p>
</div>
<div class="section" id="mandarin-lm">
<h3>Mandarin LM<a class="headerlink" href="#mandarin-lm" title="Permalink to this headline">¶</a></h3>
<p>Different from the English language model, Mandarin language model is character-based where each token is a Chinese character. We use internal corpus to train the released Mandarin language models. The corpus contain billions of tokens. The preprocessing has tiny difference from English language model and main steps include:</p>
<ul class="simple">
<li><p>The beginning and trailing whitespace characters are removed.</p></li>
<li><p>English punctuations and Chinese punctuations are removed.</p></li>
<li><p>A whitespace character between two tokens is inserted.</p></li>
</ul>
<p>Please notice that the released language models only contain Chinese simplified characters. After preprocessing done we can begin to train the language model. The key training arguments for small LM is '-o 5 --prune 0 1 2 4 4' and '-o 5' for large LM. Please refer above section for the meaning of each argument. We also convert the arpa file to binary file using default settings.</p>
</div>
</div>
<div class="section" id="kenlm">
<h2><a class="reference external" href="http://kheafield.com/code/kenlm/">KenLM</a><a class="headerlink" href="#kenlm" title="Permalink to this headline">¶</a></h2>
<p>统计语言模型工具有比较多的选择，目前使用比较好的有srilm及kenlm，其中kenlm比srilm晚出来，训练速度也更快，而且支持单机大数据的训练。现在介绍一下kenlm的使用方法。</p>
<ol>
<li><p>工具包的下载地址：http://kheafield.com/code/kenlm.tar.gz</p></li>
<li><p>使用。该工具在linux环境下使用方便。 先确保linux环境已经按照1.36.0的Boost和zlib</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">boost</span><span class="p">:</span>
<span class="n">yum</span> <span class="n">install</span> <span class="n">boost</span>
<span class="n">yum</span> <span class="n">install</span> <span class="n">boost</span><span class="o">-</span><span class="n">devel</span>

<span class="n">zlib</span><span class="p">:</span>
<span class="n">yum</span> <span class="n">install</span> <span class="n">zlib</span>
<span class="n">yum</span> <span class="n">install</span> <span class="n">zlib</span><span class="o">-</span><span class="n">devel</span>
</pre></div>
</div>
<p>然后gcc版本需要是4.8.2及以上。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wget</span> <span class="o">-</span><span class="n">O</span> <span class="o">-</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">kheafield</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">code</span><span class="o">/</span><span class="n">kenlm</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span> <span class="o">|</span><span class="n">tar</span> <span class="n">xz</span>
<span class="n">mkdir</span> <span class="n">kenlm</span><span class="o">/</span><span class="n">build</span>
<span class="n">cd</span> <span class="n">kenlm</span><span class="o">/</span><span class="n">build</span>
<span class="n">cmake</span> <span class="o">..</span>
<span class="n">make</span> <span class="o">-</span><span class="n">j2</span>
</pre></div>
</div>
</li>
<li><p>训练。使用如下命令进行训练：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">build</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">lmplz</span> <span class="o">-</span><span class="n">o</span> <span class="mi">3</span> <span class="o">--</span><span class="n">verbose_header</span> <span class="o">--</span><span class="n">text</span> <span class="n">people2014corpus_words</span><span class="o">.</span><span class="n">txt</span> <span class="o">--</span><span class="n">arpa</span> <span class="n">result</span><span class="o">/</span><span class="n">people2014corpus_words</span><span class="o">.</span><span class="n">arps</span>
</pre></div>
</div>
<p>其中，
1）people2014corpus_words.txt文件必须是分词以后的文件。</p>
<p>训练语料&lt;人民日报2014版熟语料&gt;，包括： 1）标准人工切词及词性数据people2014.tar.gz， 2）未切词文本数据people2014_words.txt， 3）kenlm训练字粒度语言模型文件及其二进制文件people2014corpus_chars.arps/klm， 4）kenlm词粒度语言模型文件及其二进制文件people2014corpus_words.arps/klm。</p>
<p>2）-o后面的5表示的是5-gram,一般取到3即可，但可以结合自己实际情况判断。</p>
</li>
<li><p>压缩。压缩模型为二进制，方便模型快速加载：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">build</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">build_binary</span> <span class="o">./</span><span class="n">result</span><span class="o">/</span><span class="n">people2014corpus_words</span><span class="o">.</span><span class="n">arps</span> <span class="o">./</span><span class="n">result</span><span class="o">/</span><span class="n">people2014corpus_words</span><span class="o">.</span><span class="n">klm</span>
</pre></div>
</div>
</li>
</ol>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="../tts/README.html" class="btn btn-neutral float-right" title="TTS" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="ppl.html" class="btn btn-neutral float-left" title="语言模型评价指标Perplexity" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, Hui Zhang.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>